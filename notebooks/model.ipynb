{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd8fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bc5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "config = SimpleNamespace()\n",
    "\n",
    "\n",
    "def update_config(config, dictionary):\n",
    "    for k, v in dictionary.items():\n",
    "        setattr(config, k, v)\n",
    "    return config\n",
    "\n",
    "\n",
    "def show_config(config: SimpleNamespace):\n",
    "    for k in sorted(config.__dict__):\n",
    "        print(f\"{k}: {getattr(config, k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e41d59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 99\n",
      "Data size: 74935\n",
      "x.shape=torch.Size([240]), y.shape=torch.Size([240])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class FaiscaDataset(Dataset):\n",
    "    def __init__(self, data: str, context_length: int):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, self.vocab_size = len(data), len(chars)\n",
    "        print(f\"Vocab size: {self.vocab_size}\")\n",
    "        print(f\"Data size: {data_size}\")\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        self.stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "        self.itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "        token_ids = [self.stoi[c] for c in data]\n",
    "\n",
    "        for i in range(0, len(token_ids) - context_length):\n",
    "            input_ids = token_ids[i : i + context_length]\n",
    "            target_ids = token_ids[i + 1 : i + context_length + 1]\n",
    "            self.input_ids.append(input_ids)\n",
    "            self.target_ids.append(target_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.target_ids[idx])\n",
    "\n",
    "    def encode(self, text: str) -> torch.Tensor:\n",
    "        return torch.tensor([self.stoi[c] for c in text], dtype=torch.long)\n",
    "\n",
    "    def decode(self, idx: torch.Tensor) -> str:\n",
    "        return \"\".join([self.itos[i.item()] for i in idx])\n",
    "\n",
    "\n",
    "with open(\"../datasets/bocage.txt\", \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "config.context_length = 240\n",
    "dataset = FaiscaDataset(text, context_length=config.context_length)\n",
    "x, y = dataset[0]\n",
    "print(f\"{x.shape=}, {y.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d12c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimension_in: int,\n",
    "        dimension_out: int,\n",
    "        context_length: int,\n",
    "        dropout: float,\n",
    "        num_heads: int,\n",
    "        qkv_bias: bool,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if dimension_out % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension_out must be divisible by num_heads, got {dimension_out} and {num_heads}\"\n",
    "            )\n",
    "\n",
    "        self.dimension_out = dimension_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dimension_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(dimension_in, dimension_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(dimension_in, dimension_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(dimension_in, dimension_out, bias=qkv_bias)\n",
    "        self.out_projection = nn.Linear(dimension_out, dimension_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, number_of_tokens, dimension_in = x.shape\n",
    "\n",
    "        # x shape: (batch_size, number_of_tokens, dimension_in)\n",
    "\n",
    "        # pass through the linear layers\n",
    "        keys = self.W_key(x)  # shape (batch_size, number_of_tokens, dimension_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # split into heads\n",
    "        keys = keys.view(\n",
    "            batch_size, number_of_tokens, self.num_heads, self.head_dim\n",
    "        )  # shape (batch_size, number_of_tokens, num_heads, head_dim)\n",
    "        queries = queries.view(\n",
    "            batch_size, number_of_tokens, self.num_heads, self.head_dim\n",
    "        )\n",
    "        values = values.view(\n",
    "            batch_size, number_of_tokens, self.num_heads, self.head_dim\n",
    "        )\n",
    "\n",
    "        # transpose to get the shape right for the attention scores\n",
    "        keys = keys.transpose(\n",
    "            1, 2\n",
    "        )  # shape (batch_size, num_heads, number_of_tokens, head_dim)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # compute the attention scores\n",
    "        attention_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        # create the mask\n",
    "        mask_bool = self.mask.bool()[:number_of_tokens, :number_of_tokens]\n",
    "\n",
    "        # apply the mask\n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        # compute the attention weights\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / keys.shape[-1] ** 0.5, dim=-1\n",
    "        )\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        # compute the context vector\n",
    "        context_vector = (attention_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # combine the heads\n",
    "        context_vector = context_vector.contiguous().view(\n",
    "            batch_size, number_of_tokens, self.dimension_out\n",
    "        )\n",
    "        context_vector = self.out_projection(context_vector)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498abbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 10, 16])\n",
      "output.shape=torch.Size([2, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttention(\n",
    "    dimension_in=16,\n",
    "    dimension_out=32,\n",
    "    context_length=10,\n",
    "    dropout=0.1,\n",
    "    num_heads=4,\n",
    "    qkv_bias=True,\n",
    ")\n",
    "\n",
    "# Example input: batch_size=2, number_of_tokens=10, dimension_in=16\n",
    "x = torch.randn(2, 10, 16)\n",
    "\n",
    "# Forward pass\n",
    "print(f\"{x.shape=}\")\n",
    "output = mha(x)\n",
    "print(f\"{output.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b6689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, embedding_dimension: int):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-6  # small constant to avoid division by zero\n",
    "        self.scale = nn.Parameter(torch.ones(embedding_dimension))\n",
    "        self.bias = nn.Parameter(torch.zeros(embedding_dimension))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03bcfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 10, 16]), mean=-0.10188867896795273, std=1.0522814989089966\n",
      "ln(x).shape=torch.Size([2, 10, 16]), mean=-5.9604645663569045e-09, std=1.0015655755996704\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(embedding_dimension=16)\n",
    "x = torch.randn(2, 10, 16)\n",
    "print(f\"{x.shape=}, mean={x.mean()}, std={x.std()}\")\n",
    "print(f\"{ln(x).shape=}, mean={ln(x).mean()}, std={ln(x).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328f77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Gelu activation:\n",
    "    xi > 0 -> output ~ xi\n",
    "    -2 < xi < 2 -> output ~ 0\n",
    "    xi << -2 -> output ~ 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (\n",
    "            0.5\n",
    "            * x\n",
    "            * (\n",
    "                1\n",
    "                + torch.tanh(\n",
    "                    torch.sqrt(torch.tensor(2.0 / torch.pi))\n",
    "                    * (x + 0.044715 * torch.pow(x, 3))\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8406c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 10, 16])\n",
      "glu(x).shape=torch.Size([2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "glu = GELU()\n",
    "x = torch.randn(2, 10, 16)\n",
    "print(f\"{x.shape=}\")\n",
    "print(f\"{glu(x).shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb987fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embedding_dimension: int, hidden_expansion_factor: int = 4):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                embedding_dimension, hidden_expansion_factor * embedding_dimension\n",
    "            ),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(\n",
    "                hidden_expansion_factor * embedding_dimension, embedding_dimension\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae428294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 10, 16])\n",
      "ff(x).shape=torch.Size([2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 10, 16)\n",
    "print(f\"{x.shape=}\")\n",
    "\n",
    "ff = FeedForward(embedding_dimension=16, hidden_expansion_factor=4)\n",
    "print(f\"{ff(x).shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e0493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dimension: int,\n",
    "        context_length: int,\n",
    "        num_heads: int,\n",
    "        qkv_bias: bool,\n",
    "        dropout_rate: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            dimension_in=embedding_dimension,\n",
    "            dimension_out=embedding_dimension,\n",
    "            context_length=context_length,\n",
    "            dropout=dropout_rate,\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "        )\n",
    "        self.feed_forward = FeedForward(\n",
    "            embedding_dimension=embedding_dimension,\n",
    "        )\n",
    "        self.norm1 = LayerNorm(embedding_dimension=embedding_dimension)\n",
    "        self.norm2 = LayerNorm(embedding_dimension=embedding_dimension)\n",
    "        self.drop_shortcut = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # shortcut connection // attention\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        # shortcut connection // feed forward\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb66c990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([2, 10, 16])\n",
      "tb(x).shape=torch.Size([2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 10, 16)\n",
    "print(f\"{x.shape=}\")\n",
    "\n",
    "tb = TransformerBlock(\n",
    "    embedding_dimension=16,\n",
    "    context_length=10,\n",
    "    num_heads=4,\n",
    "    qkv_bias=True,\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "print(f\"{tb(x).shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e99c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaiscaGPT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dimension: int,\n",
    "        context_length: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        dropout_rate: float,\n",
    "        qkv_bias: bool,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dimension)\n",
    "        self.positional_embedding = nn.Embedding(context_length, embedding_dimension)\n",
    "        self.dropout_embedding = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[\n",
    "                TransformerBlock(\n",
    "                    embedding_dimension=embedding_dimension,\n",
    "                    context_length=context_length,\n",
    "                    num_heads=num_heads,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.final_layer_norm = LayerNorm(embedding_dimension=embedding_dimension)\n",
    "        self.out_head = nn.Linear(embedding_dimension, vocab_size, bias=False)\n",
    "\n",
    "        n_params = sum(p.numel() for p in self.transformer_blocks.parameters())\n",
    "        n_params_million = n_params / 1e6\n",
    "        print(f\"Number of parameters in transformer blocks: {n_params_million:.2f}M\")\n",
    "\n",
    "        n_params_all = sum(p.numel() for p in self.parameters())\n",
    "        n_params_all_million = n_params_all / 1e6\n",
    "        print(f\"Number of parameters in all layers: {n_params_all_million:.2f}M\")\n",
    "\n",
    "    def forward(self, in_idx: torch.Tensor) -> torch.Tensor:\n",
    "        _, sequence_length = in_idx.shape\n",
    "        token_embeddings = self.token_embedding(in_idx)\n",
    "        positional_embeddings = self.positional_embedding(\n",
    "            torch.arange(sequence_length, device=in_idx.device)\n",
    "        )\n",
    "        x = token_embeddings + positional_embeddings\n",
    "        x = self.dropout_embedding(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c412062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in transformer blocks: 85.03M\n",
      "Number of parameters in all layers: 163.01M\n",
      "x.shape=torch.Size([1, 1024])\n",
      "fgpt(x).shape=torch.Size([1, 1024, 50257])\n"
     ]
    }
   ],
   "source": [
    "config = update_config(\n",
    "    config,\n",
    "    {\n",
    "        \"vocab_size\": 50257,  # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"embedding_dimension\": 768,  # Embedding dimension\n",
    "        \"num_heads\": 12,  # Number of attention heads\n",
    "        \"num_layers\": 12,  # Number of layers\n",
    "        \"dropout_rate\": 0.1,  # Dropout rate\n",
    "        \"qkv_bias\": False,  # QKV bias\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "fgpt = FaiscaGPT(\n",
    "    vocab_size=config.vocab_size,\n",
    "    embedding_dimension=config.embedding_dimension,\n",
    "    context_length=config.context_length,\n",
    "    num_layers=config.num_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    qkv_bias=config.qkv_bias,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "x = torch.randint(0, config.vocab_size, (1, config.context_length))\n",
    "\n",
    "print(f\"{x.shape=}\")\n",
    "print(f\"{fgpt(x).shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37deca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 62\n",
      "Data size: 20479\n",
      "Number of parameters in transformer blocks: 85.03M\n",
      "Number of parameters in all layers: 85.31M\n",
      "\n",
      "Input text: Hello, I am\n",
      "Encoded input: tensor([[20, 40, 47, 47, 50,  7,  1, 21,  1, 36, 48]])\n",
      "\n",
      "\n",
      "Generated: tensor([[20, 40, 47, 47, 50,  7,  1, 21,  1, 36, 48, 33,  7, 53,  4, 24, 55, 40,\n",
      "         58, 13, 48, 33, 37, 15, 44, 14, 24, 38, 38, 44, 14, 17, 15, 60, 15,  2,\n",
      "         33, 55, 10, 32, 35, 60, 56, 17, 46, 60, 16, 61, 39, 28, 18, 34, 27, 31,\n",
      "         42, 58, 27, 33, 55, 35, 60, 44, 20, 18, 10, 27,  7, 36,  5,  8,  0, 60,\n",
      "         17, 49, 17, 61, 48, 22, 17, 15, 20, 49, 47, 28, 27, 61, 39, 33, 59, 13,\n",
      "         10, 55, 46, 16, 21,  3, 27, 61, 33, 60, 10, 47, 28, 49,  7, 10, 27, 61,\n",
      "         33, 55, 57, 53, 43, 33, 32, 52, 34,  2, 44, 37,  0, 58, 44,  3, 38, 44,\n",
      "          4, 11, 58, 44, 14,  6, 55, 47, 28, 45]])\n",
      "Decoded: Hello, I amW,r'MtewAmWbCiBMcciBECyC!Wt:V_yuEkyDzdRFYPUgwPWt_yiHF:P,a(-\n",
      "yEnEzmJECHnlRPzdWxA:tkDI\"PzWy:lRn,:PzWtvrhWVqY!ib\n",
      "wi\"ci';wiB)tlRj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "config.context_length = 240\n",
    "\n",
    "bocage_text = pathlib.Path(\"../datasets/bocage-mini.txt\").read_text(\n",
    "    encoding=\"ISO-8859-1\"\n",
    ")\n",
    "dataset = FaiscaDataset(bocage_text, context_length=config.context_length)\n",
    "\n",
    "\n",
    "config = update_config(\n",
    "    config,\n",
    "    {\n",
    "        \"vocab_size\": dataset.vocab_size,  # Vocabulary size\n",
    "        \"context_length\": config.context_length,  # Context length\n",
    "        \"embedding_dimension\": 768,  # Embedding dimension\n",
    "        \"num_heads\": 12,  # Number of attention heads\n",
    "        \"num_layers\": 12,  # Number of layers\n",
    "        \"dropout_rate\": 0.1,  # Dropout rate\n",
    "        \"qkv_bias\": False,  # QKV bias\n",
    "    },\n",
    ")\n",
    "\n",
    "model = FaiscaGPT(\n",
    "    vocab_size=config.vocab_size,\n",
    "    embedding_dimension=config.embedding_dimension,\n",
    "    context_length=config.context_length,\n",
    "    num_layers=config.num_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    qkv_bias=config.qkv_bias,\n",
    ")\n",
    "\n",
    "\n",
    "input_text = \"Hello, I am\"\n",
    "encoded = dataset.encode(input_text).unsqueeze(0)\n",
    "\n",
    "print(f\"\\nInput text: {input_text}\")\n",
    "print(f\"Encoded input: {encoded}\\n\")\n",
    "\n",
    "\n",
    "max_new_tokens = 125\n",
    "\n",
    "for _ in range(max_new_tokens):\n",
    "    idx_cond = encoded[:, -config.context_length :]\n",
    "    with torch.no_grad():\n",
    "        logits = model(idx_cond)\n",
    "\n",
    "    logits = logits[:, -1, :]\n",
    "    idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "    encoded = torch.cat((encoded, idx_next), dim=1)\n",
    "\n",
    "print(f\"\\nGenerated: {encoded}\")\n",
    "decoded = dataset.decode(encoded[0])\n",
    "print(f\"Decoded: {decoded}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fe8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split index: 3035\n",
      "Batch size: 5\n",
      "Number of workers: 0\n",
      "Vocab size: 55\n",
      "Data size: 3035\n",
      "Vocab size: 62\n",
      "Data size: 17444\n",
      "namespace(context_length=240, vocab_size=62, embedding_dimension=768, num_heads=12, num_layers=12, dropout_rate=0.1, qkv_bias=False, test_size=0.15, batch_size=5, num_workers=0, shuffle=True, drop_last=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "config.test_size = 0.15\n",
    "split_idx = int(config.test_size * len(dataset))\n",
    "print(f\"Split index: {split_idx}\")\n",
    "\n",
    "config.batch_size = 5\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "\n",
    "config.num_workers = 0  # jupyter does not support multiprocessing\n",
    "print(f\"Number of workers: {config.num_workers}\")\n",
    "\n",
    "config.shuffle = True\n",
    "config.drop_last = True\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    FaiscaDataset(\n",
    "        bocage_text[:split_idx],\n",
    "        context_length=config.context_length,\n",
    "    ),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.shuffle,\n",
    "    drop_last=config.drop_last,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    FaiscaDataset(\n",
    "        bocage_text[split_idx:],\n",
    "        context_length=config.context_length,\n",
    "    ),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=config.shuffle,\n",
    "    drop_last=config.drop_last,\n",
    "    num_workers=config.num_workers,\n",
    ")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41605276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3035"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa6dd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20239"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6df2067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a067f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch: 0 - Step: 0 - Train Loss: 5.072232723236084 - Validation Loss: 6.737091064453125 - Batch: 1 (out of 559)\n",
      "Epoch: 0 - Step: 5 - Train Loss: 3.4928996562957764 - Validation Loss: 4.627834796905518 - Batch: 6 (out of 559)\n",
      "Epoch: 0 - Step: 10 - Train Loss: 3.298999547958374 - Validation Loss: 5.103976726531982 - Batch: 11 (out of 559)\n",
      "Epoch: 0 - Step: 15 - Train Loss: 3.1710705757141113 - Validation Loss: 4.973865032196045 - Batch: 16 (out of 559)\n",
      "Epoch: 0 - Step: 20 - Train Loss: 3.195740222930908 - Validation Loss: 4.918081760406494 - Batch: 21 (out of 559)\n",
      "Epoch: 0 - Step: 25 - Train Loss: 3.0871100425720215 - Validation Loss: 5.096863746643066 - Batch: 26 (out of 559)\n",
      "Epoch: 0 - Step: 30 - Train Loss: 3.0517594814300537 - Validation Loss: 5.171359062194824 - Batch: 31 (out of 559)\n",
      "Epoch: 0 - Step: 35 - Train Loss: 2.9863762855529785 - Validation Loss: 4.900959491729736 - Batch: 36 (out of 559)\n",
      "Epoch: 0 - Step: 40 - Train Loss: 2.9792404174804688 - Validation Loss: 4.8364973068237305 - Batch: 41 (out of 559)\n",
      "Epoch: 0 - Step: 45 - Train Loss: 2.8428890705108643 - Validation Loss: 5.16033935546875 - Batch: 46 (out of 559)\n",
      "Epoch: 0 - Step: 50 - Train Loss: 2.7517831325531006 - Validation Loss: 5.300332546234131 - Batch: 51 (out of 559)\n",
      "Epoch: 0 - Step: 55 - Train Loss: 2.8293228149414062 - Validation Loss: 5.293172836303711 - Batch: 56 (out of 559)\n",
      "Epoch: 0 - Step: 60 - Train Loss: 2.7702388763427734 - Validation Loss: 5.241780757904053 - Batch: 61 (out of 559)\n",
      "Epoch: 0 - Step: 65 - Train Loss: 2.707167148590088 - Validation Loss: 5.114558219909668 - Batch: 66 (out of 559)\n",
      "Epoch: 0 - Step: 70 - Train Loss: 2.6750295162200928 - Validation Loss: 5.083805561065674 - Batch: 71 (out of 559)\n",
      "Epoch: 0 - Step: 75 - Train Loss: 2.6672606468200684 - Validation Loss: 5.337754726409912 - Batch: 76 (out of 559)\n",
      "Epoch: 0 - Step: 80 - Train Loss: 2.620781421661377 - Validation Loss: 5.245384693145752 - Batch: 81 (out of 559)\n",
      "Epoch: 0 - Step: 85 - Train Loss: 2.575028419494629 - Validation Loss: 5.329244613647461 - Batch: 86 (out of 559)\n",
      "Epoch: 0 - Step: 90 - Train Loss: 2.585641384124756 - Validation Loss: 5.499743461608887 - Batch: 91 (out of 559)\n",
      "Epoch: 0 - Step: 95 - Train Loss: 2.6213302612304688 - Validation Loss: 5.568134784698486 - Batch: 96 (out of 559)\n",
      "Epoch: 0 - Step: 100 - Train Loss: 2.48042368888855 - Validation Loss: 5.438209056854248 - Batch: 101 (out of 559)\n",
      "Epoch: 0 - Step: 105 - Train Loss: 2.5254135131835938 - Validation Loss: 5.463261127471924 - Batch: 106 (out of 559)\n",
      "Epoch: 0 - Step: 110 - Train Loss: 2.534409999847412 - Validation Loss: 5.456875324249268 - Batch: 111 (out of 559)\n",
      "Epoch: 0 - Step: 115 - Train Loss: 2.5546576976776123 - Validation Loss: 5.6050567626953125 - Batch: 116 (out of 559)\n",
      "Epoch: 0 - Step: 120 - Train Loss: 2.5197596549987793 - Validation Loss: 5.8204545974731445 - Batch: 121 (out of 559)\n",
      "Epoch: 0 - Step: 125 - Train Loss: 2.5171210765838623 - Validation Loss: 5.651223182678223 - Batch: 126 (out of 559)\n",
      "Epoch: 0 - Step: 130 - Train Loss: 2.4690682888031006 - Validation Loss: 5.8065948486328125 - Batch: 131 (out of 559)\n",
      "Epoch: 0 - Step: 135 - Train Loss: 2.475471258163452 - Validation Loss: 5.806188106536865 - Batch: 136 (out of 559)\n",
      "Epoch: 0 - Step: 140 - Train Loss: 2.4288573265075684 - Validation Loss: 5.848965167999268 - Batch: 141 (out of 559)\n",
      "Epoch: 0 - Step: 145 - Train Loss: 2.451883554458618 - Validation Loss: 5.741909980773926 - Batch: 146 (out of 559)\n",
      "Epoch: 0 - Step: 150 - Train Loss: 2.418987274169922 - Validation Loss: 5.794417381286621 - Batch: 151 (out of 559)\n",
      "Epoch: 0 - Step: 155 - Train Loss: 2.4550983905792236 - Validation Loss: 5.9716877937316895 - Batch: 156 (out of 559)\n",
      "Epoch: 0 - Step: 160 - Train Loss: 2.399091958999634 - Validation Loss: 5.955956935882568 - Batch: 161 (out of 559)\n",
      "Epoch: 0 - Step: 165 - Train Loss: 2.3856542110443115 - Validation Loss: 5.925783157348633 - Batch: 166 (out of 559)\n",
      "Epoch: 0 - Step: 170 - Train Loss: 2.3896284103393555 - Validation Loss: 5.984502792358398 - Batch: 171 (out of 559)\n",
      "Epoch: 0 - Step: 175 - Train Loss: 2.3888752460479736 - Validation Loss: 5.871845722198486 - Batch: 176 (out of 559)\n",
      "Epoch: 0 - Step: 180 - Train Loss: 2.355738639831543 - Validation Loss: 5.883260726928711 - Batch: 181 (out of 559)\n",
      "Epoch: 0 - Step: 185 - Train Loss: 2.422395706176758 - Validation Loss: 5.838592052459717 - Batch: 186 (out of 559)\n",
      "Epoch: 0 - Step: 190 - Train Loss: 2.398146867752075 - Validation Loss: 5.974117279052734 - Batch: 191 (out of 559)\n",
      "Epoch: 0 - Step: 195 - Train Loss: 2.4026033878326416 - Validation Loss: 5.966970443725586 - Batch: 196 (out of 559)\n",
      "Epoch: 0 - Step: 200 - Train Loss: 2.364774703979492 - Validation Loss: 6.096653461456299 - Batch: 201 (out of 559)\n",
      "Epoch: 0 - Step: 205 - Train Loss: 2.3731889724731445 - Validation Loss: 6.06766939163208 - Batch: 206 (out of 559)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m optimizer.zero_grad()\n\u001b[32m     42\u001b[39m loss = calculate_loss(input_batch, target_batch, model)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m optimizer.step()\n\u001b[32m     45\u001b[39m tokens_seen += input_batch.numel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/faisca/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/faisca/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/faisca/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training_losses, validation_losses, track_tokens_seen = [], [], []\n",
    "tokens_seen = 0\n",
    "global_step = -1\n",
    "\n",
    "config.num_epochs = 10\n",
    "config.learning_rate = 1e-3\n",
    "config.weight_decay = 0.1\n",
    "config.device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "config.eval_freq = 5\n",
    "config.eval_iter = 1\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "\n",
    "def calculate_loss(input_batch, target_batch, model):\n",
    "    input_batch, target_batch = (\n",
    "        input_batch.to(config.device),\n",
    "        target_batch.to(config.device),\n",
    "    )\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    model.train()\n",
    "    size_train_dataloader = len(train_dataloader)\n",
    "    batch_num = 0\n",
    "\n",
    "    for input_batch, target_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = calculate_loss(input_batch, target_batch, model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "        batch_num += 1\n",
    "\n",
    "        # run evaluation\n",
    "        if global_step % config.eval_freq == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                total_train_loss = 0\n",
    "                for i, (input_batch, target_batch) in enumerate(train_dataloader):\n",
    "                    if i < config.eval_iter:\n",
    "                        loss = calculate_loss(input_batch, target_batch, model)\n",
    "                        total_train_loss += loss.item()\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                train_loss = total_train_loss / config.eval_iter\n",
    "\n",
    "                total_validation_loss = 0\n",
    "                for i, (input_batch, target_batch) in enumerate(val_dataloader):\n",
    "                    if i < config.eval_iter:\n",
    "                        loss = calculate_loss(input_batch, target_batch, model)\n",
    "                        total_validation_loss += loss.item()\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                validation_loss = total_validation_loss / config.eval_iter\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} - Step: {global_step} - Train Loss: {train_loss} - Validation Loss: {validation_loss} - Batch: {batch_num} (out of {size_train_dataloader})\"\n",
    "                )\n",
    "\n",
    "                training_losses.append(train_loss)\n",
    "                validation_losses.append(validation_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "    # print sample\n",
    "    model.eval()\n",
    "    start_context = \"Murchas no horror \"\n",
    "    context_size = model.positional_embedding.weight.shape[0]\n",
    "    encoded = dataset.encode(start_context).unsqueeze(0)\n",
    "\n",
    "    max_new_tokens = 125\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = encoded[:, -config.context_length :]\n",
    "            logits = model(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            encoded = torch.cat((encoded, idx_next), dim=1)\n",
    "\n",
    "    print(f\"\\nGenerated: {encoded}\")\n",
    "    decoded = dataset.decode(encoded[0])\n",
    "    print(f\"Decoded: {decoded}\\n\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07474cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 16\n",
      "context_length: 240\n",
      "device: mps\n",
      "drop_last: True\n",
      "dropout_rate: 0.1\n",
      "embedding_dimension: 768\n",
      "learning_rate: 0.001\n",
      "num_epochs: 3\n",
      "num_heads: 12\n",
      "num_layers: 12\n",
      "num_workers: 4\n",
      "qkv_bias: False\n",
      "shuffle: True\n",
      "test_size: 0.15\n",
      "vocab_size: 99\n",
      "weight_decay: 0.1\n"
     ]
    }
   ],
   "source": [
    "show_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23382dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
